{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckUsRGrokBwT"
      },
      "outputs": [],
      "source": [
        "# Instalação dos pacotes necessários\n",
        "!pip install openai-whisper gTTS ffmpeg-python numpy torch\n",
        "\n",
        "import whisper, os, time, base64, wave, contextlib, subprocess\n",
        "from gtts import gTTS\n",
        "from datetime import datetime\n",
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import files, output\n",
        "\n",
        "# Função para gravar pelo navegador\n",
        "def gravar_navegador(segundos=5, nome_arquivo=\"entrada.wav\"):\n",
        "    if segundos > 60:\n",
        "        segundos = 60\n",
        "        print(\"Tempo solicitado maior que 60 segundos. Restrito para 60 segundos.\")\n",
        "    RECORD = f\"\"\"\n",
        "    const sleep = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "    const b2text = blob => new Promise(resolve => {{\n",
        "      const reader = new FileReader()\n",
        "      reader.onloadend = e => resolve(e.target.result)\n",
        "      reader.readAsDataURL(blob)\n",
        "    }})\n",
        "    var record = async function() {{\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({{ audio: true }})\n",
        "      const recorder = new MediaRecorder(stream)\n",
        "      let data = []\n",
        "      recorder.ondataavailable = event => data.push(event.data)\n",
        "      recorder.start()\n",
        "      await sleep({segundos*1000})\n",
        "      recorder.stop()\n",
        "      await new Promise(resolve => recorder.onstop = resolve)\n",
        "      const audioBlob = new Blob(data, {{ type: 'audio/wav' }})\n",
        "      const base64data = await b2text(audioBlob)\n",
        "      google.colab.kernel.invokeFunction('notebook.saveAudio', [base64data], {{}})\n",
        "    }}\n",
        "    record()\n",
        "    \"\"\"\n",
        "    display(Javascript(RECORD))\n",
        "\n",
        "# Callback para salvar o áudio gravado\n",
        "def saveAudio(b64data):\n",
        "    header, data = b64data.split(',', 1)\n",
        "    audio = base64.b64decode(data)\n",
        "    with open(\"entrada.wav\", \"wb\") as f:\n",
        "        f.write(audio)\n",
        "    print(\"Áudio gravado pelo navegador e salvo como entrada.wav\")\n",
        "\n",
        "output.register_callback('notebook.saveAudio', saveAudio)\n",
        "\n",
        "# Função para checar duração e cortar se necessário\n",
        "def cortar_audio(arquivo, limite=60):\n",
        "    try:\n",
        "        with contextlib.closing(wave.open(arquivo,'r')) as f:\n",
        "            frames = f.getnframes()\n",
        "            rate = f.getframerate()\n",
        "            duracao = frames / float(rate)\n",
        "        if duracao > limite:\n",
        "            print(f\"Atenção: o áudio tem {duracao:.2f} segundos. Será cortado para {limite} segundos.\")\n",
        "            arquivo_cortado = \"entrada_cortada.wav\"\n",
        "            subprocess.run([\n",
        "                \"ffmpeg\", \"-y\", \"-i\", arquivo,\n",
        "                \"-t\", str(limite),\n",
        "                arquivo_cortado\n",
        "            ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            return arquivo_cortado\n",
        "        else:\n",
        "            print(f\"Duração do áudio: {duracao:.2f} segundos.\")\n",
        "            return arquivo\n",
        "    except:\n",
        "        print(\"Não foi possível calcular a duração (formato não WAV). O Whisper ainda tentará processar.\")\n",
        "        return arquivo\n",
        "\n",
        "# Funções auxiliares\n",
        "def transcrever_audio(arquivo):\n",
        "    modelo = whisper.load_model(\"base\")\n",
        "    resultado = modelo.transcribe(arquivo)\n",
        "    return resultado[\"text\"]\n",
        "\n",
        "def falar_texto(texto, arquivo=\"resposta.mp3\"):\n",
        "    tts = gTTS(text=texto, lang=\"pt\")\n",
        "    tts.save(arquivo)\n",
        "    display(Audio(arquivo))\n",
        "\n",
        "# Fluxo principal\n",
        "def main():\n",
        "    inicio = time.time()\n",
        "    momento_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    print(\"Escolha a opção de entrada:\")\n",
        "    print(\"1 - Gravar pelo navegador (até 60 segundos)\")\n",
        "    print(\"2 - Fazer upload de arquivo (até 60 segundos)\")\n",
        "    escolha = input(\"Digite 1 ou 2: \")\n",
        "\n",
        "    if escolha == \"1\":\n",
        "        segundos = int(input(\"Digite o tempo de gravação em segundos (máx 60): \"))\n",
        "        gravar_navegador(segundos=segundos)\n",
        "        arquivo_audio = \"entrada.wav\"\n",
        "        print(\"Após a gravação, o arquivo será salvo como entrada.wav\")\n",
        "    else:\n",
        "        uploaded = files.upload()\n",
        "        arquivo_audio = list(uploaded.keys())[0]\n",
        "        arquivo_audio = cortar_audio(arquivo_audio, limite=60)\n",
        "\n",
        "    texto_transcrito = transcrever_audio(arquivo_audio)\n",
        "    momento_transcricao = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"Transcrição ({momento_transcricao}): {texto_transcrito}\")\n",
        "\n",
        "    falar_texto(texto_transcrito)\n",
        "    momento_resposta = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    fim = time.time()\n",
        "    tempo_total = fim - inicio\n",
        "    print(f\"Data/hora da gravação: {momento_inicio}\")\n",
        "    print(f\"Data/hora da transcrição: {momento_transcricao}\")\n",
        "    print(f\"Data/hora da resposta (voz sintetizada): {momento_resposta}\")\n",
        "    print(f\"Tempo total do fluxo: {tempo_total:.2f} segundos\")\n",
        "\n",
        "main()\n"
      ]
    }
  ]
}